{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
    "# from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "from tokenizers import BertWordPieceTokenizer, ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    work_path = os.path.dirname(os.path.abspath('.'))\n",
    "    input_path = os.path.join(work_path, \"input\")\n",
    "    data_path = os.path.join(input_path, \"tweet-sentiment-extraction\")\n",
    "    train_path = os.path.join(data_path, 'train.csv')\n",
    "    test_path = os.path.join(data_path, 'test.csv')\n",
    "    sample_submission_path = os.path.join(data_path, 'sample_submission.csv')\n",
    "    model_path = os.path.join(work_path, \"model\")\n",
    "    for path in [model_path]:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #     暂时没有截取，有很多符号的，长度不止110\n",
    "#     暂时没有截取，有很多符号的，长度不止110\n",
    "#     max_seq_len = 110\n",
    "    max_seq_len = 128\n",
    "    n_splits = 5\n",
    "    patience_epoch = 2\n",
    "    \n",
    "    batch_size = 32\n",
    "    epochs_num = 1\n",
    "    train_print_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class model_config:\n",
    "# model_name = 'bert'\n",
    "#     pretrain_model_name = 'bert-base-uncased'\n",
    "#     pretrain_model_path = os.path.join(config.input_path, pretrain_model_name)\n",
    "#     tokenizer = BertWordPieceTokenizer('{}/vocab.txt'.format(pretrain_model_path), lowercase=True)\n",
    "#     learning_rate = 5e-5\n",
    "#     adjust_lr_num = 0\n",
    "\n",
    "class model_config:\n",
    "    model_name = 'roberta'\n",
    "    pretrain_model_name = 'roberta-base'\n",
    "    pretrain_model_path = os.path.join(config.input_path, pretrain_model_name)\n",
    "    tokenizer = ByteLevelBPETokenizer(\n",
    "        vocab_file='{}/vocab.json'.format(pretrain_model_path), \n",
    "        merges_file='{}/merges.txt'.format(pretrain_model_path), \n",
    "        lowercase=True,\n",
    "        add_prefix_space=True\n",
    "    )\n",
    "    learning_rate = 5e-5  \n",
    "    adjust_lr_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def jaccard(str1, str2):\n",
    "    a = set(str1.lower().split())\n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "\n",
    "def get_selected_text(text, sentiment, start_idx, end_idx, offsets):\n",
    "    # Set the predicted output as the original tweet when the tweet's sentiment is \"neutral\",\n",
    "    # or the tweet only contains one word\n",
    "    if sentiment == \"neutral\" or len(text.split()) < 2:\n",
    "        selected_text = text\n",
    "        return selected_text\n",
    "    selected_text = \"\"\n",
    "    for ix in range(start_idx, end_idx + 1):\n",
    "        selected_text += text[offsets[ix][0]: offsets[ix][1]]\n",
    "        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n",
    "            selected_text += \" \"\n",
    "    return selected_text\n",
    "\n",
    "\n",
    "def calculate_jaccard_score(text, true_selected_text, sentiment, pred_start_idx, pred_end_idx, offsets):\n",
    "    \"\"\"\n",
    "    Calculate the jaccard score from the predicted span and the actual span for a batch of tweets\n",
    "    \"\"\"\n",
    "    # A span's end index has to be greater than or equal to the start index\n",
    "    # If this doesn't hold, the start index is set to equal the end index (the span is a single token)\n",
    "    if pred_end_idx < pred_start_idx:\n",
    "        pred_end_idx = pred_start_idx\n",
    "    pred_selected_text = get_selected_text(text, sentiment, pred_start_idx, pred_end_idx, offsets)\n",
    "    score = jaccard(true_selected_text.strip(), pred_selected_text.strip())\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_score(y_true_list, y_pred_list):\n",
    "    jaccard_score = 0\n",
    "    for y_true, y_pred in zip(y_true_list, y_pred_list):\n",
    "        text = y_true[0]\n",
    "        selected_text = y_true[1]\n",
    "        sentiment = y_true[2]\n",
    "        offsets = y_true[3]\n",
    "        pred_start_idx = y_pred[0]\n",
    "        pred_end_idx = y_pred[1]\n",
    "\n",
    "        score = calculate_jaccard_score(text, selected_text, sentiment, pred_start_idx, pred_end_idx, offsets)\n",
    "        jaccard_score += score\n",
    "    return jaccard_score / len(y_true_list)\n",
    "\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        # self.x_data = []\n",
    "        # self.y_data = []\n",
    "        # for i, row in df.iterrows():\n",
    "        #     x, y = self.row_to_tensor(self.tokenizer, row)\n",
    "        #     self.x_data.append(x)\n",
    "        #     self.y_data.append(y)\n",
    "        self.data = []\n",
    "        for i, row in df.iterrows():\n",
    "            data = self.row_to_tensor(row)\n",
    "            try:\n",
    "                assert len(data[\"ids\"]) == config.max_seq_len\n",
    "                assert len(data['attention_mask']) == config.max_seq_len\n",
    "                assert len(data[\"token_type_ids\"]) == config.max_seq_len\n",
    "                assert len(data[\"offsets\"]) == config.max_seq_len\n",
    "            except:\n",
    "                print(data)\n",
    "                print('ids:{}'.format(len(data[\"ids\"])))\n",
    "                print('attention_mask:{}'.format(len(data[\"attention_mask\"])))\n",
    "                print('token_type_ids:{}'.format(len(data[\"token_type_ids\"])))\n",
    "                print('offsets:{}'.format(len(data[\"offsets\"])))\n",
    "            # tmp = {\n",
    "            #     'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            #     'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            #     'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            #     'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            #     'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            #     'sentiment': data[\"sentiment\"],\n",
    "            #     'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "            # }\n",
    "            if self.mode in ['train', 'val']:\n",
    "                start_idx, end_idx = self.get_target_idx(row, data['tweet'], data['offsets'])\n",
    "                data['selected_text'] = row['selected_text']\n",
    "                data['start_idx'] = start_idx\n",
    "                data['end_idx'] = end_idx\n",
    "            data['sentiment'] = row['sentiment']\n",
    "            self.data.append(data)\n",
    "\n",
    "    def get_target_idx(self, row, tweet, offsets):\n",
    "        selected_text = \" \" + \" \".join(row.selected_text.lower().split())\n",
    "\n",
    "        len_st = len(selected_text) - 1\n",
    "        idx0 = None\n",
    "        idx1 = None\n",
    "\n",
    "        for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "            if \" \" + tweet[ind: ind + len_st] == selected_text:\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st - 1\n",
    "                break\n",
    "\n",
    "        char_targets = [0] * len(tweet)\n",
    "        if idx0 != None and idx1 != None:\n",
    "            for ct in range(idx0, idx1 + 1):\n",
    "                char_targets[ct] = 1\n",
    "\n",
    "        target_idx = []\n",
    "        for j, (offset1, offset2) in enumerate(offsets):\n",
    "            if sum(char_targets[offset1: offset2]) > 0:\n",
    "                target_idx.append(j)\n",
    "\n",
    "        start_idx = target_idx[0]\n",
    "        end_idx = target_idx[-1]\n",
    "\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    def row_to_tensor(self, row):\n",
    "        tweet = \" \" + \" \".join(row.text.lower().split())\n",
    "        encoding = self.tokenizer.encode(tweet)\n",
    "        sentiment_id = self.tokenizer.encode(row.sentiment).ids\n",
    "        ids = [0] + sentiment_id + [2, 2] + encoding.ids + [2]\n",
    "        token_type_ids = [0, 0, 0, 0] + [0] * (len(encoding.ids) + 1)\n",
    "        offsets = [(0, 0)] * 4 + encoding.offsets + [(0, 0)]\n",
    "\n",
    "        pad_len = config.max_seq_len - len(ids)\n",
    "        if pad_len > 0:\n",
    "            ids += [1] * pad_len\n",
    "            token_type_ids = token_type_ids + ([0] * pad_len)\n",
    "            offsets += [(0, 0)] * pad_len\n",
    "\n",
    "        ids = torch.tensor(ids)\n",
    "        attention_mask = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "        offsets = torch.tensor(offsets)\n",
    "\n",
    "        data = dict()\n",
    "        data['tweet'] = tweet\n",
    "        data['ids'] = ids\n",
    "        data['attention_mask'] = attention_mask\n",
    "        data['token_type_ids'] = token_type_ids\n",
    "        data['offsets'] = offsets\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return self.x_data[index], self.y_data[index]\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.y_data)\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model/roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = RobertaConfig.from_pretrained(model_config.pretrain_model_path)\n",
    "        self.config.output_hidden_states = True\n",
    "        self.model = RobertaModel.from_pretrained(model_config.pretrain_model_path, config=self.config)\n",
    "        self.config.output_hidden_states = True\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        # self.classifier = nn.Linear(self.config.hidden_size * 2, 2)\n",
    "        self.classifier = nn.Linear(self.config.hidden_size, 2)\n",
    "        torch.nn.init.normal_(self.classifier.weight, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None,\n",
    "                position_ids=None, head_mask=None):\n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        hidden_states = outputs[2]\n",
    "        # out = torch.cat((hidden_states[-1], hidden_states[-2]), dim=-1)\n",
    "        out = torch.stack([hidden_states[-1], hidden_states[-2], hidden_states[-3]])\n",
    "        out = torch.mean(out, 0)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.classifier(out)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "\n",
    "        start_logits = start_logits.squeeze(-1) \n",
    "        end_logits = end_logits.squeeze(-1) \n",
    "\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_config.model_name\n",
    "tokenizer = model_config.tokenizer\n",
    "\n",
    "def model_predict(model, test_loader):\n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            tweet = inputs[\"tweet\"]\n",
    "            sentiment = inputs[\"sentiment\"]\n",
    "            ids = inputs[\"ids\"]\n",
    "            token_type_ids = inputs[\"token_type_ids\"]\n",
    "            attention_mask = inputs[\"attention_mask\"]\n",
    "            offsets = inputs[\"offsets\"]\n",
    "            ids = ids.to(config.device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(config.device, dtype=torch.long)\n",
    "            attention_mask = attention_mask.to(config.device, dtype=torch.long)\n",
    "            start_logits, end_logits = model(\n",
    "                input_ids=ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "            )\n",
    "            pred_start_probs = torch.softmax(start_logits, dim=1).cpu().data.numpy()\n",
    "            pred_end_probs = torch.softmax(end_logits, dim=1).cpu().data.numpy()\n",
    "            for i in range(len(tweet)):\n",
    "                y_true_list.append((tweet[i], sentiment[i], offsets[i]))\n",
    "                y_pred_list.append((pred_start_probs[i], pred_end_probs[i]))\n",
    "    return y_true_list, y_pred_list\n",
    "    \n",
    "def get_pred_list(y_true_list, preds_dict):\n",
    "    data_len = len(y_true_list)\n",
    "    y_pred_list = []\n",
    "    mode = 2\n",
    "    if mode == 1:\n",
    "        for i in range(data_len):\n",
    "            preds = []\n",
    "            for fold_idx in range(config.n_splits):\n",
    "                prob = preds_dict['{}'.format(fold_idx)][i]\n",
    "                pred = np.argmax(prob)\n",
    "                preds.append(pred)\n",
    "            # pred_set = set([x for x in preds])\n",
    "            label_id = max(preds, key=preds.count)\n",
    "            y_pred_list.append(label_id)\n",
    "    else:\n",
    "        for i in range(data_len):\n",
    "            start_logits, end_logits = None, None\n",
    "            for fold_idx in range(config.n_splits):\n",
    "                if start_logits is None:\n",
    "                    start_logits, end_logits = preds_dict['{}'.format(fold_idx)][i]\n",
    "                else:\n",
    "                    tmp1, tmp2 = preds_dict['{}'.format(fold_idx)][i]\n",
    "                    start_logits += tmp1\n",
    "                    end_logits += tmp2\n",
    "            y_pred_list.append((np.argmax(start_logits), np.argmax(end_logits)))\n",
    "            \n",
    "    pred_list = []\n",
    "    for y_true, y_pred in zip(y_true_list, y_pred_list):\n",
    "        text = y_true[0]\n",
    "        sentiment = y_true[1]\n",
    "        offsets = y_true[2]\n",
    "        pred_start_idx = y_pred[0]\n",
    "        pred_end_idx = y_pred[1]\n",
    "        pred = get_selected_text(text, sentiment, pred_start_idx, pred_end_idx, offsets)\n",
    "        pred_list.append(pred)\n",
    "    return pred_list\n",
    "\n",
    "def predict():\n",
    "    test_df = pd.read_csv(config.test_path)\n",
    "    test_df = test_df[:100]\n",
    "    test_df.loc[:, 'selected_text'] = test_df.text.values\n",
    "\n",
    "    test_dataset = MyDataset(test_df, tokenizer, 'test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)\n",
    "\n",
    "    preds_dict = dict()\n",
    "    y_true_list = []\n",
    "    for fold_idx in range(config.n_splits):\n",
    "        model = Model().to(config.device)\n",
    "        model_save_path = os.path.join(config.model_path, '{}_fold{}.bin'.format(model_name, fold_idx))\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        y_true_list, y_pred_list = model_predict(model, test_loader)\n",
    "#         submission = pd.DataFrame(pred_list)\n",
    "#         submission.to_csv('{}/{}_fold{}_submission.csv'\n",
    "#                           .format(config.submission_path, model_name, fold_idx), index=False, header=False)\n",
    "        preds_dict['{}'.format(fold_idx)] = y_pred_list\n",
    "    pred_list = get_pred_list(y_true_list, preds_dict)\n",
    "\n",
    "    submission = pd.read_csv(config.sample_submission_path)\n",
    "    submission = submission[:100]\n",
    "    submission['selected_text'] = pred_list\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}