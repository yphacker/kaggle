{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/zengyaner/predict-future-sales-2-0?scriptVersionId=19789132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing \n",
    "from xgboost import plot_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_features(booster, figsize):    \n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax)\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float16)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    return df\n",
    "\n",
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/kaggle/input/all-datta5/data2.pkl')\n",
    "# data = data[[\n",
    "#     'date_block_num', \n",
    "#     'shop_id', \n",
    "#     'item_id', \n",
    "#     'item_cnt_month',\n",
    "    \n",
    "# #     'shop_city', \n",
    "# #     'shop_name1',\n",
    "# #     'shop_type', \n",
    "    \n",
    "# #     'name_1', \n",
    "# #     'name_2', \n",
    "# #     'name_3',\n",
    "    \n",
    "# #     'item_type', \n",
    "# #     'item_subtype', \n",
    "# #     'item_category_id', \n",
    "    \n",
    "# #     'item_cnt_month_lag_1',\n",
    "# #     'item_cnt_month_lag_2', \n",
    "# #     'item_cnt_month_lag_3',\n",
    "# #     'date_block_num_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_item_id_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_item_id_avg_item_cnt_lag_2',\n",
    "# #     'date_block_num_and_item_id_avg_item_cnt_lag_3',\n",
    "# #     'date_block_num_and_shop_id_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_id_avg_item_cnt_lag_2',\n",
    "# #     'date_block_num_and_shop_id_avg_item_cnt_lag_3',\n",
    "    \n",
    "# #     'date_block_num_and_shop_city_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_name1_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_type_avg_item_cnt_lag_1',\n",
    "    \n",
    "# #     'date_block_num_and_item_category_id_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_item_type_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_item_subtype_avg_item_cnt_lag_1',\n",
    "    \n",
    "# #     'date_block_num_and_shop_id_and_item_id_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_id_and_name_1_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_id_and_name_2_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_id_and_name_3_avg_item_cnt_lag_1',\n",
    "# #     'date_block_num_and_shop_id_and_item_category_id_avg_item_cnt_lag_1',\n",
    "    \n",
    "# #     'delta_price_lag', \n",
    "# #     'item_shop_last_sale', \n",
    "# #     'item_last_sale',\n",
    "# #     'item_first_sale', \n",
    "# #     'year', \n",
    "# #     'month', \n",
    "# #     'days'\n",
    "# ]]\n",
    "\n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##求出每个月的均值销售额##shop_mean_months\n",
    "a = []\n",
    "for i in range(3,34):\n",
    "    b = data[data.date_block_num==i]##取到每一个月\n",
    "    c = b.sum()['item_cnt_month']#求和\n",
    "    d = len(b.shop_id.unique())#长度（个数）\n",
    "    a.append(c/d)#求得均值\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import *                                 #支持中文\n",
    "\n",
    "# ax.plot(range(4,34), a, marker='o', mec='r', mfc='w',label='shop_mean_month')\n",
    "# ax.legend()  # 让图例生效\n",
    "\n",
    "plt.subplots(1,1,figsize=(14,10))\n",
    "plt.plot(range(4,34), a, marker='o', mec='r', mfc='w',label='shop_mean_month')\n",
    "plt.legend()  # 让图例生效\n",
    "plt.xlabel('month') #X轴标签\n",
    "plt.ylabel(\"shop_mean_month\") #Y轴标签\n",
    "plt.title(\"shop_mean_month\") #标题\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##添加周特征，周的每一天的特征\n",
    "weekarr = []\n",
    "t = 2\n",
    "count = 0\n",
    "for w in range(3):\n",
    "    for i in [31,28,31,30,31,30,31,31,30,31,30,31]:\n",
    "        a = [0,0,0,0,0,0,0,count]\n",
    "        count+=1\n",
    "        for j in range(i):\n",
    "            a[t]+=1\n",
    "            if t==6:\n",
    "                t=-1\n",
    "            t+=1\n",
    "        weekarr.append(a)\n",
    "weekarr = pd.DataFrame(np.vstack(weekarr), columns=['week0','week1','week2','week3','week4','week5','week6','date_block_num'])\n",
    "data = pd.merge(data, weekarr, on=['date_block_num'], how='left')#加进去\n",
    "del weekarr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据集的划分\n",
    "X_zong = data.drop(['item_cnt_month'], axis=1)#去掉标签\n",
    "Y_train = data[data.date_block_num < 33]['item_cnt_month']#训练集的标签\n",
    "Y_valid = data[data.date_block_num == 33]['item_cnt_month']#交叉验证的标签\n",
    "del data##删除数据集减少占用内存\n",
    "gc.collect()##垃圾回收机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler ##数据归一化\n",
    "minMax = MinMaxScaler()    \n",
    "\n",
    "\n",
    "X_zong_std = minMax.fit_transform(X_zong.iloc[:,:-7])  ##取所有的行，除了后七列的所有的\n",
    "X_zong.iloc[:,:-7] = pd.DataFrame(np.vstack(X_zong_std),columns=X_zong.columns[:-7])\n",
    "X_zong.iloc[:,:-7] = downcast_dtypes(X_zong.iloc[:,:-7])#转换数据类型，为了减少内存\n",
    "\n",
    "##这就是排除出去的后七列\n",
    "X_zong['week0'] = X_zong['week0'].astype(np.int8)\n",
    "X_zong['week1'] = X_zong['week1'].astype(np.int8)\n",
    "X_zong['week2'] = X_zong['week2'].astype(np.int8)\n",
    "X_zong['week3'] = X_zong['week3'].astype(np.int8)\n",
    "X_zong['week4'] = X_zong['week4'].astype(np.int8)\n",
    "X_zong['week5'] = X_zong['week5'].astype(np.int8)\n",
    "X_zong['week6'] = X_zong['week6'].astype(np.int8)\n",
    "\n",
    "del X_zong_std\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_zong[X_zong.date_block_num < 0.96679688]\n",
    "X_valid = X_zong[X_zong.date_block_num == 0.96679688]\n",
    "X_test = X_zong[X_zong.date_block_num == 1]\n",
    "del X_zong\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##参数可以自己改\n",
    "ts = time.time()\n",
    "\n",
    "model = XGBRegressor(\n",
    "    max_depth=10,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=0.5, \n",
    "    colsample_bytree=0.9, \n",
    "    subsample=0.8, \n",
    "    eta=0.1,    \n",
    "    seed=1)\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 10)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(model, (10,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_test).clip(0, 20)##clip0-20之间\n",
    "test = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test.index, \n",
    "    \"item_cnt_month\": Y_test\n",
    "})\n",
    "submission.to_csv('xgb_submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
